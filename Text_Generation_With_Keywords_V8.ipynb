{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation With Keywords - V8.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id4FAGTvhAiH"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyslOsl7wuP7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiBLJZO3g1zs"
      },
      "source": [
        "Load spacy, disable 'ner' and 'parser', keep tagger only. require GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2J36n5vfykE",
        "outputId": "e64add48-1a9c-4c0b-f2d4-4f91be1a757e"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.disable_pipes('ner', 'parser')\n",
        "#spacy.require_gpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f8c12f5cbb0>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f8c12f5cc90>)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E20u4zya2ovX",
        "outputId": "5303fe76-e86c-475b-a720-c74642911493"
      },
      "source": [
        "print(nlp.pipe_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqUzZHlYhhtd"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4QySKGsPaOC",
        "outputId": "4b56a0b9-50ed-431f-b54b-8476cfa5817c"
      },
      "source": [
        "#\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hef4t84QxxmU"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwbFJsVzLLlf"
      },
      "source": [
        "NOUN VERB ADJECTIVE ADVERB - consider adding pronouns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWOnpqfAhshK"
      },
      "source": [
        "Read data and save as a list where each element is a tuple of lists which are: (keywords, keywords_pos, template, sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7T1YCkbELQs"
      },
      "source": [
        "# fine grained pos tags\n",
        "#pos_tags = ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'RB', 'RBR', 'RBS', \n",
        "#           'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "# coarse grained pos tags\n",
        "keyword_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
        "def read_data(filepath):\n",
        "  data = []\n",
        "\n",
        "  with open(filepath) as f:\n",
        "    # the sentences are the labels\n",
        "    labels = [sentence[:-1] for sentence in f]\n",
        "    for doc in nlp.pipe(labels, batch_size=2000, n_process=10): \n",
        "      # templates are the POS tags of the sentence\n",
        "      template = list(map(lambda word : word.pos_, doc))\n",
        "      # sentence as list of words (sentence is the gold standard reference)\n",
        "      label = [str(token).lower() for token in doc]\n",
        "      # extract (and lemmatize) keywords\n",
        "      keywords = extract_keywords(doc)\n",
        "      # get keywords pos tags (individually)\n",
        "      keywords_pos = list(map(lambda word: extract_pos(nlp(word)), keywords))\n",
        "      data.append((keywords, keywords_pos, template, label))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvHrYUpvz8a2"
      },
      "source": [
        "# Find words in a sentence whose POS tag is a noun, verb, adjective or adverb. Lemmatize and store as keyword.\n",
        "def extract_keywords(doc):\n",
        "  kw = []\n",
        "  for word in doc:\n",
        "    if word.pos_ in keyword_tags:\n",
        "      kw.append(nlp(str(word).lower())[0].lemma_)\n",
        "  return kw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFiuX1c5Vu3t"
      },
      "source": [
        "# Extract pos of a single word (Individually, no context)\n",
        "def extract_pos(word):\n",
        "  return word[0].pos_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-L_9yfh_WZK1"
      },
      "source": [
        "# Read data (Article dataset)\n",
        "#train_pre = read_data('drive/MyDrive/TGP/trainset_article.txt')\n",
        "#with open('drive/MyDrive/TGP/article_train.txt', 'wb') as f1:\n",
        "#  pickle.dump(train_pre, f1)\n",
        "#test_pre = read_data('drive/MyDrive/TGP/testset_article.txt')\n",
        "#with open('drive/MyDrive/TGP/article_test.txt', 'wb') as f2:\n",
        "#  pickle.dump(test_pre, f2)\n",
        "#valid_pre = read_data('drive/MyDrive/TGP/devset_article.txt')\n",
        "#with open('drive/MyDrive/TGP/article_valid.txt', 'wb') as f3:\n",
        "#  pickle.dump(valid_pre, f3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfLHGpslfOTU"
      },
      "source": [
        "#currentFile = open('drive/MyDrive/TGP/article_train.txt', mode='rb')\n",
        "#data = pickle.load(currentFile)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxbcn6-TOi2r"
      },
      "source": [
        "# Read data (Quotes dataset)\n",
        "#train_pre = read_data('drive/MyDrive/TGP/train.txt')\n",
        "#test_pre = read_data('drive/MyDrive/TGP/test.txt')\n",
        "#valid_pre = read_data('drive/MyDrive/TGP/valid.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlKdjyG6xCP6"
      },
      "source": [
        "# Save data file on Google Drive\n",
        "#with open('drive/MyDrive/TGP/article_train.txt', 'wb') as f1:\n",
        "#  pickle.dump(train_pre, f1)\n",
        "#with open('drive/MyDrive/TGP/article_test.txt', 'wb') as f2:\n",
        "#  pickle.dump(test_pre, f1)\n",
        "#with open('drive/MyDrive/TGP/article_valid.txt', 'wb') as f3:\n",
        "#  pickle.dump(valid_pre, f1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4VZ-E2WQ4y"
      },
      "source": [
        "'''# Load data file from google drive (fixed version)\n",
        "currentFile = open('drive/MyDrive/TGP/training_data_v2.txt', mode='rb')\n",
        "data = pickle.load(currentFile)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksfA5-TH_ToH"
      },
      "source": [
        "currentFile = open('drive/MyDrive/TGP/valid_data.txt', mode='rb')\n",
        "data = pickle.load(currentFile)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOrtNU5ZxeOy"
      },
      "source": [
        "# Define function for sorting that returns the length of the sentence as key\n",
        "def sortKey(e):\n",
        "  return len(e[3])"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGgIIascycX0"
      },
      "source": [
        "# Sort data according to the length of a sentence\n",
        "data.sort(key=sortKey)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IP6LsZtN0Wl"
      },
      "source": [
        "# Add start and end of sentence tokens - \"<sos>\", \"<eos>\"\n",
        "for i, (kw, kw_pos, template, sentence) in enumerate(data):\n",
        "  template = [\"<sos>\"] + template + [\"<eos>\"]\n",
        "  # For sentence we only use the <sos> token for generation\n",
        "  sentence = [\"<sos>\"] + sentence\n",
        "  data[i] = (kw, kw_pos, template, sentence)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0RNeh4A1Ec5L",
        "outputId": "de5d74cd-dccf-48d8-d512-3c8d3aa23f62"
      },
      "source": [
        "'''nlp.disable_pipes('tagger')\n",
        "print(nlp.pipe_names)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"nlp.disable_pipes('tagger')\\nprint(nlp.pipe_names)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUpLDJX4-nKg"
      },
      "source": [
        "# **Data Loading**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp85FUu899xE"
      },
      "source": [
        "currentFile = open('drive/MyDrive/TGP/prepared_train.txt', mode='rb')\n",
        "training_data = pickle.load(currentFile)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR3oEVnlDSB1"
      },
      "source": [
        "currentFile = open('drive/MyDrive/TGP/prepared_valid.txt', mode='rb')\n",
        "validation_data = pickle.load(currentFile)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLR664EaEMKw",
        "outputId": "3c32250c-2fca-49b4-f25f-03d931508087"
      },
      "source": [
        "len(training_data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "249945"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c0x-7xnKENXW",
        "outputId": "4bf9742c-9b46-4a5d-a66e-e85a1dcdfe62"
      },
      "source": [
        "len(validation_data)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "37468"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-NL-hwWEh5j"
      },
      "source": [
        "# For GPU VRAM testing\n",
        "training_data.reverse()\n",
        "validation_data.reverse()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6jvNpn8yxSa"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke-pVhtGvD46"
      },
      "source": [
        "The following Vocab class is served as a dictionary that maps words and tags into Ids. The __unk__ token is used for words that are not part of the training data, while __pad__ token is used as padding value (0). <sos> and <eos> are start and end of sentence tokens respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PiO6av5xoSW"
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self):\n",
        "      self.word2id = {\"__pad__\": 0, \"__unk__\": 1, \"<sos>\": 2}\n",
        "      self.id2word = {0: \"__pad__\", 1: \"__unk__\", 2: \"<sos>\"}\n",
        "      self.n_words = 2\n",
        "        \n",
        "      self.tag2id = {\"__pad__\": 0, \"<sos>\": 1, \"<eos>\": 2, 'ADJ':3, 'ADP':4, 'ADV':5, 'AUX':6, 'CONJ':7, \n",
        "                     'CCONJ':8, 'DET':9, 'INTJ':10, 'NOUN':11, 'NUM':12, 'PART':13, 'PRON':14, 'PROPN':15, \n",
        "                     'PUNCT':16, 'SCONJ':17, 'SYM':18, 'VERB':19, 'X':20, 'SPACE':21}\n",
        "      self.id2tag = {v:k for (k, v) in self.tag2id.items()}\n",
        "        \n",
        "    def index_words(self, words):\n",
        "      word_indexes = [self.index_word(w) for w in words]\n",
        "      return word_indexes\n",
        "\n",
        "    def index_tags(self, tags):\n",
        "      tag_indexes = [self.tag2id[t] for t in tags]\n",
        "      return tag_indexes\n",
        "    \n",
        "    def index_word(self, w):\n",
        "        if w not in self.word2id:\n",
        "          self.n_words += 1\n",
        "          self.word2id[w] = self.n_words\n",
        "          self.id2word[self.n_words] = w\n",
        "        return self.word2id[w]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSE69bNHwQSn"
      },
      "source": [
        "# Function for creating a new vocabulary from the words in the training data\n",
        "def create_vocabulary(data):\n",
        "    vocab = Vocab()\n",
        "    for (keywords, _, _, sentence) in data:\n",
        "      for token in sentence:\n",
        "        vocab.index_word(token)\n",
        "      for keyword in keywords:\n",
        "        vocab.index_word(keyword)\n",
        "      \n",
        "    return vocab"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg0HinJ71a1c"
      },
      "source": [
        "vocab = create_vocabulary(training_data)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzDFT_Smo61n",
        "outputId": "c7089219-1c2d-4818-b665-b47a4f000506"
      },
      "source": [
        "vocab.n_words"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83126"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH8uaiGRHpHf"
      },
      "source": [
        "# For test and validation data: convert unknown words to \"__unk__\" tag\n",
        "def convert_unk(data):\n",
        "  for i, (kw, kw_pos, template, sentence) in enumerate(data):\n",
        "    new_kw = []\n",
        "    new_sentence = []\n",
        "    for keyword in kw:\n",
        "      keyword = keyword if keyword in vocab.word2id.keys() else \"__unk__\"\n",
        "      new_kw.append(keyword)\n",
        "    for word in sentence:\n",
        "      word = word if word in vocab.word2id.keys() else \"__unk__\"\n",
        "      new_sentence.append(word)\n",
        "    \n",
        "    validation_data[i] = (new_kw, kw_pos, template, new_sentence)\n",
        "  \n",
        "  return validation_data"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5LAkUHsJo92"
      },
      "source": [
        "validation_data = convert_unk(validation_data)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazJgbqPytHT"
      },
      "source": [
        "# Use the Vocab object to convert the data from strings to integers\n",
        "def convert_data(data, vocab):\n",
        "  int_data = []\n",
        "  for (keywords, keywords_pos, template, sentence) in data:\n",
        "    int_kw = [vocab.word2id[keyword] for keyword in keywords]\n",
        "    int_kw_pos = [vocab.tag2id[keyword_pos] for keyword_pos in keywords_pos]\n",
        "    int_template = [vocab.tag2id[pos] for pos in template]\n",
        "    int_sentence = [vocab.word2id[word] for word in sentence]\n",
        "    int_data.append((int_kw, int_kw_pos, int_template, int_sentence))\n",
        "  \n",
        "  return int_data"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwIlezaRH4xK"
      },
      "source": [
        "training_data = convert_data(training_data, vocab)\n",
        "validation_data = convert_data(validation_data, vocab)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf7PiNN5-d0r"
      },
      "source": [
        "# Create batches and pad relevant input data\n",
        "def create_batches(data, batch_size=64):\n",
        "  # The list to store all instances and corresponding labels\n",
        "  data_batches = []\n",
        "  # Keyword batch to store in data_batches\n",
        "  kw_batch = []\n",
        "  # Keyword pos batch to store in data_batches\n",
        "  kw_pos_batch = []\n",
        "  # Template batch to store in data_batches \n",
        "  template_batch = []\n",
        "  # Store lengths of each instance in template batch for packing\n",
        "  template_len = []\n",
        "  # Sentence batch to store in data_batches\n",
        "  sentence_batch = []\n",
        "  \n",
        "  for i, (keywords, keywords_pos, template, sentence) in enumerate(data):\n",
        "    kw_batch.append(torch.LongTensor(keywords))\n",
        "    kw_pos_batch.append(torch.LongTensor(keywords_pos))\n",
        "    template_batch.append(torch.LongTensor(template))\n",
        "    template_len.append(len(template))\n",
        "    sentence_batch.append(torch.LongTensor(sentence))\n",
        "\n",
        "    if (i + 1) % batch_size == 0:\n",
        "      # Pad batchs of size batch_size\n",
        "      kw_batch = torch.nn.utils.rnn.pad_sequence(kw_batch, batch_first=True)\n",
        "      kw_pos_batch = torch.nn.utils.rnn.pad_sequence(kw_pos_batch, batch_first=True)\n",
        "      template_batch = torch.nn.utils.rnn.pad_sequence(template_batch, batch_first=True)\n",
        "      sentence_batch = torch.nn.utils.rnn.pad_sequence(sentence_batch, batch_first=True)\n",
        "\n",
        "      data_batches.append((kw_batch, kw_pos_batch, (template_batch, template_len), sentence_batch))\n",
        "      \n",
        "      # Reinitialize the batches\n",
        "      kw_batch = []\n",
        "      kw_pos_batch = []\n",
        "      template_batch = []\n",
        "      template_len = []\n",
        "      sentence_batch = []\n",
        "      label_batch = []\n",
        "    \n",
        "  return data_batches"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw3uIXGWnkqN"
      },
      "source": [
        "training_data = create_batches(training_data)\n",
        "validation_data = create_batches(validation_data)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmmG1FQYixlN"
      },
      "source": [
        "# **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHxDjQLkuM8u"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, w_embed_dim=500, tag_embed_dim=57):\n",
        "    super(Generator, self).__init__()\n",
        "    # Embedding layer for words (shared between keywords and sentences)\n",
        "    self.word_embed = nn.Embedding(num_embeddings=vocab.n_words, embedding_dim=w_embed_dim, padding_idx=0)\n",
        "    # Embedding layer for pos tags (shared between keyword tags and templates)\n",
        "    self.tag_embed = nn.Embedding(num_embeddings=len(vocab.tag2id), embedding_dim=tag_embed_dim, padding_idx=0)\n",
        "    \n",
        "    # Keyword encoder\n",
        "    self.kw_encoder = FFNN(w_embed_dim)\n",
        "    # Template encoder\n",
        "    self.template_encoder = TemplateEncoder(tag_embed_dim)\n",
        "    # Max Tag Overlap (template and keyword tag matching)\n",
        "    self.mto = MTO(1)\n",
        "    # Attention layer\n",
        "    self.attn = Attention()\n",
        "    # Decoder\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "\n",
        "  def forward(self, kw, kw_pos, template_pack, sentence, tr_ratio=0.5):    \n",
        "    # Keyword encoder\n",
        "    kw_embed = self.word_embed(kw)\n",
        "    encoded_kw = self.kw_encoder(kw_embed)\n",
        "\n",
        "    # Template encoder\n",
        "    template, template_len = template_pack\n",
        "    template_embed = self.tag_embed(template)\n",
        "    packed_template = torch.nn.utils.rnn.pack_padded_sequence(template_embed, template_len, \n",
        "                                                              batch_first=True, enforce_sorted=False)\n",
        "    outputs, last_hidden = self.template_encoder(packed_template)\n",
        "    # Embed keyword pos tags\n",
        "    kw_pos_embed = self.tag_embed(kw_pos)\n",
        "\n",
        "    # Get lambda weights from Max Tag Overlap\n",
        "    lambdas, lambdas_c = self.mto(template_embed, kw_pos_embed)\n",
        "\n",
        "    # Embed sentence\n",
        "    sentence_embed = self.word_embed(sentence)\n",
        "\n",
        "    # First input is the <sos> token\n",
        "    input = sentence_embed[:, 0, :].unsqueeze(1)\n",
        "\n",
        "    # Initialize hidden layer for decoder\n",
        "    hidden = torch.zeros(8, sentence.size(0), 500).cuda() \n",
        "\n",
        "    # Initialize mask to ignore padded values in attention mechanism \n",
        "    mask = torch.any((kw_embed != 0), dim=2).cuda()\n",
        "\n",
        "    # List to store predictions\n",
        "    preds = []\n",
        "    for t in range(1, sentence_embed.size(1)):\n",
        "      # Use attention to calculate context vector\n",
        "      a = self.attn(outputs[:,t,:], last_hidden, encoded_kw, mask)\n",
        "      context = torch.bmm(a.unsqueeze(1), encoded_kw)\n",
        "      # Multiply this time step's context by its weight lambda\n",
        "      context *= lambdas[:,t,:].unsqueeze(1)\n",
        "      # Multiply this time step's template encoding by its weight lambda c (1 minus lambda)\n",
        "      htt =  outputs[:,t,:].unsqueeze(1) * lambdas[:,t,:].unsqueeze(1)\n",
        "      # mt is tanh of the concatenation of context and current time step's encoded template\n",
        "      mt = torch.tanh(torch.cat((context, htt), dim=2))\n",
        "      # Input to the decoder is the concatenation of mt and the embedding of a word from current time step t\n",
        "      decoder_input = torch.cat((input, mt), dim=2)\n",
        "      # Decode\n",
        "      pred, hidden, last_hidden = self.decoder(decoder_input, hidden)\n",
        "      # Store the prediction\n",
        "      preds.append(pred)\n",
        "      # Calculate next input, unless it's the last iteration\n",
        "      if t < sentence_embed.size(1) - 1:\n",
        "        # Teacher force mechanism (If true, feed next layer with ground truth)\n",
        "        teacher_force = torch.rand(1).item() < tr_ratio\n",
        "        # The last prediction with the highest probability\n",
        "        last_pred = torch.argmax(pred, dim = 1).cuda()\n",
        "        # If teacher_force is true, use ground truth, else the last prediction\n",
        "        input = sentence_embed[:, t, :].unsqueeze(1) if teacher_force else self.word_embed(last_pred.unsqueeze(1))\n",
        "    \n",
        "    return torch.stack(preds, dim=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J8JtGA6jqB3"
      },
      "source": [
        "# Keyword encoder - Fully connected neural network\n",
        "class FFNN(nn.Module):\n",
        "  def __init__(self, h_dim):\n",
        "    super(FFNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(h_dim, h_dim)\n",
        "    self.lrelu1 = nn.LeakyReLU(0.01)\n",
        "    self.fc2 = nn.Linear(h_dim, h_dim)\n",
        "    self.lrelu2 = nn.LeakyReLU(0.01)\n",
        "    self.fc3 = nn.Linear(h_dim, h_dim)\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.lrelu1(self.fc1(x))\n",
        "    x = self.lrelu2(self.fc2(x))\n",
        "    x = torch.tanh(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X3TCtqgSYWM"
      },
      "source": [
        "# Template encoder - stack of bidirectional GRU's and MLP's to reduce the dimension for the decoder.\n",
        "class TemplateEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, h_size=100):\n",
        "    super(TemplateEncoder, self).__init__()\n",
        "    self.gru = nn.GRU(input_size=input_dim, hidden_size=h_size, num_layers=4, batch_first=True, \n",
        "                      dropout=0.5, bidirectional=True)\n",
        "    self.fc = nn.Linear(2*h_size, 2*h_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    outputs, hidden = self.gru(x)\n",
        "    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n",
        "\n",
        "    return outputs, hidden"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THJJzVGi7GOC"
      },
      "source": [
        "# Template and keyword tag matching (Max Tag Overlap)\n",
        "class MTO(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(MTO, self).__init__()\n",
        "    self.fc = nn.Linear(input_size, input_size)\n",
        "\n",
        "  def forward(self, template_embed, kw_pos_embed):\n",
        "    # Calculate s - the max cosine similarity between each template tag and keyword tag\n",
        "    s_batch = []\n",
        "    for template_tags, keyword_tags in zip(template_embed, kw_pos_embed):\n",
        "      s = []\n",
        "      for t_pos in template_tags:\n",
        "        s.append(torch.max(F.cosine_similarity(keyword_tags, t_pos.unsqueeze(0))).item())\n",
        "      s_batch.append(torch.tensor(s))\n",
        "\n",
        "    s_batch = torch.stack(s_batch).unsqueeze(2)\n",
        "    s_batch = s_batch.cuda()\n",
        "\n",
        "    # Lambdas are weights which are equal to s going into a sigmoid on top of a linear layer \n",
        "    lambdas = torch.sigmoid(self.fc(s_batch))\n",
        "    # Lambda_c is 1-lambda for each weight lambda in lambdas\n",
        "    lambdas_c = torch.add(torch.multiply(lambdas, -1), 1)\n",
        "\n",
        "    return lambdas, lambdas_c"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5tDnIYxxp4y"
      },
      "source": [
        "# Attention layer (additive attention)\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Attention, self).__init__()\n",
        "    self.w = torch.nn.Linear(900, 500)\n",
        "    self.v = nn.Linear(500, 1, bias=False)\n",
        "\n",
        "  def forward(self, enc_template_o, hidden, encoded_kw, mask):\n",
        "    # Unsqueeze for repeat\n",
        "    hidden = hidden.unsqueeze(1)\n",
        "    enc_template_o = enc_template_o.unsqueeze(1)\n",
        "    # Repeat for stacking\n",
        "    hidden = hidden.repeat(1, encoded_kw.size(1), 1)\n",
        "    enc_template_o = enc_template_o.repeat(1, encoded_kw.size(1), 1)\n",
        "    # Conatenate last hidden layer, the encoded keywords and the encoded template\n",
        "    energy = torch.tanh(self.w(torch.cat((hidden, encoded_kw, enc_template_o), dim=2)))\n",
        "    # Calculate score\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "    # Mask\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMFzdn85fjS"
      },
      "source": [
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, h_size=500, n_layers=4):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.gru = nn.GRU(input_size=1200, hidden_size=500, num_layers=4, batch_first=True, \n",
        "                      dropout=0.5, bidirectional=True)\n",
        "    self.fc = nn.Linear(1000, 200)\n",
        "    self.fc_out = nn.Linear(2200, vocab.n_words)\n",
        "\n",
        "  def forward(self, gru_input, hidden_input):\n",
        "    outputs, hidden = self.gru(gru_input, hidden_input)\n",
        "    # Last hidden layers for attention\n",
        "    last_hidden = torch.tanh(self.fc(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n",
        "    prediction = self.fc_out(torch.cat((outputs.squeeze(1), gru_input.squeeze(1)), dim=1))\n",
        "    return prediction, hidden, last_hidden"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrJgLnPZfMos"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1M-NydnkSdH"
      },
      "source": [
        "Notes to self: \n",
        "- Read the article in NLP projects folder to decide num of layers of GRU in encoder and decoder\n",
        "\n",
        "- Add a dropout layer after embeddings\n",
        "\n",
        "- Try teacher forcing\n",
        "\n",
        "- For initialization of decoder hidden states, try random noise (or something else) instead of zeros\n",
        "\n",
        "- Use learning rate decay\n",
        "\n",
        "- Use gradient clipping\n",
        "\n",
        "- Check if replacing -PRON- with the actual word improves performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNmOGfmWfQey"
      },
      "source": [
        "# Initialize the model\n",
        "model = Generator().cuda()\n",
        "\n",
        "# Load saved model\n",
        "#model.load_state_dict(torch.load(\"drive/MyDrive/model_9_epoch\"))\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n",
        "\n",
        "# Step learning rate scheduler, lr = 0.5*lr every 10 epochs\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5trGwONroptI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "9256ec4b-ecb5-42cf-810e-f4fd5712ef38"
      },
      "source": [
        "'''def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)'''"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"def init_weights(m):\\n    for name, param in m.named_parameters():\\n        if 'weight' in name:\\n            nn.init.normal_(param.data, mean=0, std=0.01)\\n        else:\\n            nn.init.constant_(param.data, 0)\\n            \\nmodel.apply(init_weights)\""
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZsLHuQ2H3bW5"
      },
      "source": [
        "Evaluation function for validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPLyYv-93nY3"
      },
      "source": [
        "def evaluate(model, valid_set, criterion):\n",
        "  # Change model to evaluation mode\n",
        "  model.eval()\n",
        "  \n",
        "  epoch_loss = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i, (kw, kw_pos, (template, template_len), sentence) in enumerate(valid_set, 1):\n",
        "      kw = kw.cuda()\n",
        "      kw_pos = kw_pos.cuda()\n",
        "      template = template.cuda()\n",
        "      sentence = sentence.cuda()\n",
        "\n",
        "      output = model(kw, kw_pos, (template, template_len), sentence, 0)\n",
        "      loss = criterion(output.reshape(-1, output.shape[-1]), sentence[:, 1:].reshape(-1))\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "  \n",
        "  return epoch_loss / len(valid_set)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4Eet5iX3oRB"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnzP5gid0Srn"
      },
      "source": [
        "# Training loop\n",
        "def train_loop(model, n_epochs, train_set, valid_set, tr_ratio):\n",
        "  \n",
        "  for e in range(1, n_epochs + 1):\n",
        "    # Activate model training mode\n",
        "    model.train()\n",
        "    # Reset epoch loss\n",
        "    t_epoch_loss = 0\n",
        "\n",
        "    for i, (kw, kw_pos, (template, template_len), sentence) in enumerate(train_set, 1):\n",
        "      kw = kw.cuda()\n",
        "      kw_pos = kw_pos.cuda()\n",
        "      template = template.cuda()\n",
        "      sentence = sentence.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(kw, kw_pos, (template, template_len), sentence, tr_ratio)\n",
        "      loss = criterion(output.reshape(-1, output.shape[-1]), sentence[:, 1:].reshape(-1))\n",
        "      loss.backward()\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "      optimizer.step()\n",
        "      t_epoch_loss += loss.item()\n",
        "\n",
        "      #print(f\"batch {i}\")\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler.step()\n",
        "    # Save model every epoch\n",
        "    torch.save(model.state_dict(), f\"drive/MyDrive/model\") \n",
        "    # Calculate validation loss\n",
        "    v_epoch_loss = evaluate(model, valid_set, criterion)\n",
        "\n",
        "    # Print training and validation epoch loss\n",
        "    print(f\"Epoch {e} train loss: {t_epoch_loss / len(train_set)}\")\n",
        "    print(f\"Epoch {e} validation loss: {v_epoch_loss / len(valid_set)}\")\n",
        "    \n",
        "\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "ggXYsco21OfX",
        "outputId": "4bd00039-f542-45e0-ad84-17b959eba376"
      },
      "source": [
        "train_loop(model, 40, training_data, validation_data, 0.5)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-0aa305117b6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-34-17343f87d338>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(model, n_epochs, train_set, valid_set, tr_ratio)\u001b[0m\n\u001b[1;32m     17\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplate_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5DcFRCKjf_L",
        "outputId": "8932c48c-5638-4e13-d624-0f33fd68f15f"
      },
      "source": [
        "b"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-cw14i7uOZR"
      },
      "source": [
        "# **Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sTzJbqJuS_0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wljQbIIyRC9o"
      },
      "source": [
        "# **TESTS**"
      ]
    }
  ]
}