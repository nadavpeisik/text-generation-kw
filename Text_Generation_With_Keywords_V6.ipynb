{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation With Keywords - V6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "id4FAGTvhAiH"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyslOsl7wuP7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import pickle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiBLJZO3g1zs"
      },
      "source": [
        "Load spacy, disable 'ner' and 'parser', keep tagger only. require GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2J36n5vfykE",
        "outputId": "f8936f9c-fe62-482e-e692-66c98268f47b"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "nlp.disable_pipes('ner', 'parser')\n",
        "#spacy.require_gpu()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f50802c0130>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f50802c00c0>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E20u4zya2ovX",
        "outputId": "01acb80d-7409-4192-ddda-233397f002d3"
      },
      "source": [
        "print(nlp.pipe_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tagger']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqUzZHlYhhtd"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4QySKGsPaOC",
        "outputId": "c740a1c5-21a2-4dfa-c0e6-102b1ad8f2f5"
      },
      "source": [
        "#\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hef4t84QxxmU"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwbFJsVzLLlf"
      },
      "source": [
        "NOUN VERB ADJECTIVE ADVERB - consider adding pronouns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWOnpqfAhshK"
      },
      "source": [
        "Read data and save as a list where each element is a tuple of lists which are: (keywords, keywords_pos, template, sentence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7T1YCkbELQs"
      },
      "source": [
        "# fine grained pos tags\n",
        "#pos_tags = ['JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS', 'RB', 'RBR', 'RBS', \n",
        "#           'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "# coarse grained pos tags\n",
        "keyword_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
        "def read_data(filepath):\n",
        "  data = []\n",
        "\n",
        "  with open(filepath) as f:\n",
        "    # the sentences are the labels\n",
        "    labels = [sentence[:-1] for sentence in f]\n",
        "    for doc in nlp.pipe(labels, batch_size=2000, n_process=10): \n",
        "      # templates are the POS tags of the sentence\n",
        "      template = list(map(lambda word : word.pos_, doc))\n",
        "      # sentence as list of words (sentence is the gold standard reference)\n",
        "      label = [str(token).lower() for token in doc]\n",
        "      # extract (and lemmatize) keywords\n",
        "      keywords = extract_keywords(doc)\n",
        "      # get keywords pos tags (individually)\n",
        "      keywords_pos = list(map(lambda word: extract_pos(nlp(word)), keywords))\n",
        "      data.append((keywords, keywords_pos, template, label))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvHrYUpvz8a2"
      },
      "source": [
        "# Find words in a sentence whose POS tag is a noun, verb, adjective or adverb. Lemmatize and store as keyword.\n",
        "def extract_keywords(doc):\n",
        "  kw = []\n",
        "  for word in doc:\n",
        "    if word.pos_ in keyword_tags:\n",
        "      kw.append(nlp(str(word).lower())[0].lemma_)\n",
        "  return kw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFiuX1c5Vu3t"
      },
      "source": [
        "# Extract pos of a single word (Individually, no context)\n",
        "def extract_pos(word):\n",
        "  return word[0].pos_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zxbcn6-TOi2r"
      },
      "source": [
        "'''# Read data\n",
        "train_pre = read_data('drive/MyDrive/TGP/train.txt')\n",
        "#test_pre = read_data('drive/MyDrive/TGP/test.txt')\n",
        "#valid_pre = read_data('drive/MyDrive/TGP/valid.txt')'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlKdjyG6xCP6"
      },
      "source": [
        "'''# Save data file on Google Drive\n",
        "with open('drive/MyDrive/TGP/training_data_v2.txt', 'wb') as f1:\n",
        "  pickle.dump(train_pre, f1)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj4VZ-E2WQ4y"
      },
      "source": [
        "'''# Load data file from google drive (fixed version)\n",
        "currentFile = open('drive/MyDrive/TGP/training_data_v2.txt', mode='rb')\n",
        "data = pickle.load(currentFile)'''"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp85FUu899xE"
      },
      "source": [
        "currentFile = open('drive/MyDrive/TGP/prepared_train.txt', mode='rb')\n",
        "data = pickle.load(currentFile)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOrtNU5ZxeOy"
      },
      "source": [
        "# Define function for sorting that returns the length of the sentence as key\n",
        "def sortKey(e):\n",
        "  return len(e[3])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGgIIascycX0"
      },
      "source": [
        "# Sort data according to the length of a sentence\n",
        "data.sort(key=sortKey)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IP6LsZtN0Wl"
      },
      "source": [
        "# Add start and end of sentence tokens - \"<sos>\", \"<eos>\"\n",
        "for i, (kw, kw_pos, template, sentence) in enumerate(data):\n",
        "  template = [\"<sos>\"] + template + [\"<eos>\"]\n",
        "  # For sentence we only use the <sos> token for generation\n",
        "  sentence = [\"<sos>\"] + sentence\n",
        "  data[i] = (kw, kw_pos, template, sentence)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFbmIqFKLeZI",
        "outputId": "df51f391-4a1d-4194-d2cb-70d15f5319db"
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "250000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HsyceSi0dWM5",
        "outputId": "21699499-dfdb-44d5-ffa3-f03e245d9285"
      },
      "source": [
        "len(data[-1][3])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6jvNpn8yxSa"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewRSuQOFKn5p"
      },
      "source": [
        "'''with open('drive/MyDrive/TGP/prepared_train.txt', 'wb') as f1:\n",
        "  pickle.dump(data, f1)'''"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVrEbnpMKq2P"
      },
      "source": [
        "'''currentFile = open('drive/MyDrive/TGP/prepared_train.txt', mode='rb')\n",
        "data = pickle.load(currentFile)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEXQ43bOwg0E"
      },
      "source": [
        "data.reverse()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0RNeh4A1Ec5L",
        "outputId": "de5d74cd-dccf-48d8-d512-3c8d3aa23f62"
      },
      "source": [
        "'''nlp.disable_pipes('tagger')\n",
        "print(nlp.pipe_names)'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"nlp.disable_pipes('tagger')\\nprint(nlp.pipe_names)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ke-pVhtGvD46"
      },
      "source": [
        "The following Vocab class is served as a dictionary that maps words and tags into Ids. The __unk__ token is used for words that are not part of the training data, while __pad__ token is used as padding value (0). <sos> and <eos> are start and end of sentence tokens respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PiO6av5xoSW"
      },
      "source": [
        "class Vocab:\n",
        "    def __init__(self):\n",
        "      self.word2id = {\"__pad__\": 0, \"__unk__\": 1, \"<sos>\": 2}\n",
        "      self.id2word = {0: \"__pad__\", 1: \"__unk__\", 2: \"<sos>\"}\n",
        "      self.n_words = 2\n",
        "        \n",
        "      self.tag2id = {\"__pad__\": 0, \"<sos>\": 1, \"<eos>\": 2, 'ADJ':3, 'ADP':4, 'ADV':5, 'AUX':6, 'CONJ':7, \n",
        "                     'CCONJ':8, 'DET':9, 'INTJ':10, 'NOUN':11, 'NUM':12, 'PART':13, 'PRON':14, 'PROPN':15, \n",
        "                     'PUNCT':16, 'SCONJ':17, 'SYM':18, 'VERB':19, 'X':20, 'SPACE':21}\n",
        "      self.id2tag = {v:k for (k, v) in self.tag2id.items()}\n",
        "        \n",
        "    def index_words(self, words):\n",
        "      word_indexes = [self.index_word(w) for w in words]\n",
        "      return word_indexes\n",
        "\n",
        "    def index_tags(self, tags):\n",
        "      tag_indexes = [self.tag2id[t] for t in tags]\n",
        "      return tag_indexes\n",
        "    \n",
        "    def index_word(self, w):\n",
        "        if w not in self.word2id:\n",
        "          self.n_words += 1\n",
        "          self.word2id[w] = self.n_words\n",
        "          self.id2word[self.n_words] = w\n",
        "        return self.word2id[w]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSE69bNHwQSn"
      },
      "source": [
        "# Function for creating a new vocabulary from the words in the training data\n",
        "def create_vocabulary(data):\n",
        "    vocab = Vocab()\n",
        "    for (keywords, _, _, sentence) in data:\n",
        "      for token in sentence:\n",
        "        vocab.index_word(token)\n",
        "      for keyword in keywords:\n",
        "        vocab.index_word(keyword)\n",
        "      \n",
        "    return vocab"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg0HinJ71a1c"
      },
      "source": [
        "vocab = create_vocabulary(data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzDFT_Smo61n",
        "outputId": "97a37a39-2ccb-433e-f0c6-0013c0536657"
      },
      "source": [
        "vocab.n_words"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "83138"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Cx4hH5RzVI"
      },
      "source": [
        "REMINDER: Check if replacing -PRON- with the actual word improves performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xazJgbqPytHT"
      },
      "source": [
        "# Use the Vocab object to convert the data from strings to integers\n",
        "def convert_data(data, vocab):\n",
        "  int_data = []\n",
        "  for (keywords, keywords_pos, template, sentence) in data:\n",
        "    int_kw = [vocab.word2id[keyword] for keyword in keywords]\n",
        "    int_kw_pos = [vocab.tag2id[keyword_pos] for keyword_pos in keywords_pos]\n",
        "    int_template = [vocab.tag2id[pos] for pos in template]\n",
        "    int_sentence = [vocab.word2id[word] for word in sentence]\n",
        "    int_data.append((int_kw, int_kw_pos, int_template, int_sentence))\n",
        "  \n",
        "  return int_data"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwIlezaRH4xK"
      },
      "source": [
        "data = convert_data(data, vocab)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lf7PiNN5-d0r"
      },
      "source": [
        "# Create batches and pad relevant input data\n",
        "# Templates are going into GRU so they will be packed instead of padded.\n",
        "def create_batches(data, batch_size=64):\n",
        "  # The list to store all instances and corresponding labels\n",
        "  data_batches = []\n",
        "  # Keyword batch to store in data_batches\n",
        "  kw_batch = []\n",
        "  # Keyword pos batch to store in data_batches\n",
        "  kw_pos_batch = []\n",
        "  # Template batch to store in data_batches \n",
        "  template_batch = []\n",
        "  # Store lengths of each instance in template batch for packing\n",
        "  template_len = []\n",
        "  # Sentence batch to store in data_batches\n",
        "  sentence_batch = []\n",
        "  \n",
        "  for i, (keywords, keywords_pos, template, sentence) in enumerate(data):\n",
        "    kw_batch.append(torch.LongTensor(keywords))\n",
        "    kw_pos_batch.append(torch.LongTensor(keywords_pos))\n",
        "    template_batch.append(torch.LongTensor(template))\n",
        "    template_len.append(len(template))\n",
        "    sentence_batch.append(torch.LongTensor(sentence))\n",
        "\n",
        "    if (i + 1) % batch_size == 0:\n",
        "      # Pad batchs of size batch_size\n",
        "      kw_batch = torch.nn.utils.rnn.pad_sequence(kw_batch, batch_first=True)\n",
        "      kw_pos_batch = torch.nn.utils.rnn.pad_sequence(kw_pos_batch, batch_first=True)\n",
        "      template_batch = torch.nn.utils.rnn.pad_sequence(template_batch, batch_first=True)\n",
        "      sentence_batch = torch.nn.utils.rnn.pad_sequence(sentence_batch, batch_first=True)\n",
        "\n",
        "      data_batches.append((kw_batch, kw_pos_batch, (template_batch, template_len), sentence_batch))\n",
        "      \n",
        "      # Reinitialize the batches\n",
        "      kw_batch = []\n",
        "      kw_pos_batch = []\n",
        "      template_batch = []\n",
        "      template_len = []\n",
        "      sentence_batch = []\n",
        "      label_batch = []\n",
        "    \n",
        "  return data_batches"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw3uIXGWnkqN"
      },
      "source": [
        "data = create_batches(data)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmmG1FQYixlN"
      },
      "source": [
        "# **Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHxDjQLkuM8u"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, w_embed_dim=500, tag_embed_dim=57):\n",
        "    super(Generator, self).__init__()\n",
        "    # Embedding layer for words (shared between keywords and sentences)\n",
        "    self.word_embed = nn.Embedding(num_embeddings=vocab.n_words, embedding_dim=w_embed_dim, padding_idx=0)\n",
        "    # Embedding layer for pos tags (shared between keyword tags and templates)\n",
        "    self.tag_embed = nn.Embedding(num_embeddings=len(vocab.tag2id), embedding_dim=tag_embed_dim, padding_idx=0)\n",
        "    \n",
        "    # Keyword encoder\n",
        "    self.kw_encoder = FFNN(w_embed_dim)\n",
        "    # Template encoder\n",
        "    self.template_encoder = TemplateEncoder(tag_embed_dim)\n",
        "    # Max Tag Overlap (template and keyword tag matching)\n",
        "    self.mto = MTO(1)\n",
        "    # Attention layer\n",
        "    self.attn = Attention()\n",
        "    # Decoder\n",
        "    self.decoder = Decoder()\n",
        "\n",
        "\n",
        "  def forward(self, kw, kw_pos, template_pack, sentence):    \n",
        "    # Keyword encoder\n",
        "    kw_embed = self.word_embed(kw)\n",
        "    encoded_kw = self.kw_encoder(kw_embed)\n",
        "\n",
        "    # Template encoder\n",
        "    template, template_len = template_pack\n",
        "    template_embed = self.tag_embed(template)\n",
        "    packed_template = torch.nn.utils.rnn.pack_padded_sequence(template_embed, template_len, \n",
        "                                                              batch_first=True, enforce_sorted=False)\n",
        "    outputs, last_hidden = self.template_encoder(packed_template)\n",
        "    # Embed keyword pos tags\n",
        "    kw_pos_embed = self.tag_embed(kw_pos)\n",
        "\n",
        "    # Get lambda weights from Max Tag Overlap\n",
        "    lambdas, lambdas_c = self.mto(template_embed, kw_pos_embed)\n",
        "\n",
        "    # Embed sentence\n",
        "    sentence_embed = self.word_embed(sentence)\n",
        "\n",
        "    # First input is the <sos> token\n",
        "    input = sentence_embed[:, 0, :].unsqueeze(1)\n",
        "\n",
        "    # Initialize hidden layer for decoder\n",
        "    hidden = torch.zeros(8, sentence.size(0), 500).cuda() \n",
        "\n",
        "    # Initialize mask to ignore padded values in attention mechanism \n",
        "    mask = torch.any((kw_embed != 0), dim=2).cuda()\n",
        "\n",
        "    # List to store predictions\n",
        "    preds = []\n",
        "    for t in range(1, sentence_embed.size(1)):\n",
        "      # Use attention to calculate context vector\n",
        "      a = self.attn(outputs[:,t,:], last_hidden, encoded_kw, mask)\n",
        "      context = torch.bmm(a.unsqueeze(1), encoded_kw)\n",
        "      # Multiply this time step's context by its weight lambda\n",
        "      context *= lambdas[:,t,:].unsqueeze(1)\n",
        "      # Multiply this time step's template encoding by its weight lambda c (1 minus lambda)\n",
        "      htt =  outputs[:,t,:].unsqueeze(1) * lambdas[:,t,:].unsqueeze(1)\n",
        "      # mt is tanh of the concatenation of context and current time step's encoded template\n",
        "      mt = torch.tanh(torch.cat((context, htt), dim=2))\n",
        "      # Input to the decoder is the concatenation of mt and the embedding of a word from current time step t\n",
        "      decoder_input = torch.cat((input, mt), dim=2)\n",
        "      # Decode\n",
        "      pred, hidden, last_hidden = self.decoder(decoder_input, hidden)\n",
        "      # Store the highest probability prediction\n",
        "      preds.append(pred)\n",
        "    \n",
        "    return torch.stack(preds, dim=1)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J8JtGA6jqB3"
      },
      "source": [
        "# Keyword encoder - Fully connected neural network\n",
        "class FFNN(nn.Module):\n",
        "  def __init__(self, h_dim):\n",
        "    super(FFNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(h_dim, h_dim)\n",
        "    self.lrelu1 = nn.LeakyReLU(0.01)\n",
        "    self.fc2 = nn.Linear(h_dim, h_dim)\n",
        "    self.lrelu2 = nn.LeakyReLU(0.01)\n",
        "    self.fc3 = nn.Linear(h_dim, h_dim)\n",
        "  \n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.lrelu1(self.fc1(x))\n",
        "    x = self.lrelu2(self.fc2(x))\n",
        "    x = torch.tanh(self.fc3(x))\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X3TCtqgSYWM"
      },
      "source": [
        "# Template encoder - stack of bidirectional GRU's and MLP's to reduce the dimension for the decoder.\n",
        "class TemplateEncoder(nn.Module):\n",
        "  def __init__(self, input_dim, h_size=100):\n",
        "    super(TemplateEncoder, self).__init__()\n",
        "    self.gru = nn.GRU(input_size=input_dim, hidden_size=h_size, num_layers=4, batch_first=True, \n",
        "                      dropout=0.5, bidirectional=True)\n",
        "    self.fc = nn.Linear(2*h_size, 2*h_size)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    outputs, hidden = self.gru(x)\n",
        "    outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "    hidden = torch.tanh(self.fc(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n",
        "\n",
        "    return outputs, hidden"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THJJzVGi7GOC"
      },
      "source": [
        "# Template and keyword tag matching (Max Tag Overlap)\n",
        "class MTO(nn.Module):\n",
        "  def __init__(self, input_size):\n",
        "    super(MTO, self).__init__()\n",
        "    self.fc = nn.Linear(input_size, input_size)\n",
        "\n",
        "  def forward(self, template_embed, kw_pos_embed):\n",
        "    # Calculate s - the max cosine similarity between each template tag and keyword tag\n",
        "    s_batch = []\n",
        "    for template_tags, keyword_tags in zip(template_embed, kw_pos_embed):\n",
        "      s = []\n",
        "      for t_pos in template_tags:\n",
        "        s.append(torch.max(F.cosine_similarity(keyword_tags, t_pos.unsqueeze(0))).item())\n",
        "      s_batch.append(torch.tensor(s))\n",
        "\n",
        "    s_batch = torch.stack(s_batch).unsqueeze(2)\n",
        "    s_batch = s_batch.cuda()\n",
        "\n",
        "    # Lambdas are weights which are equal to s going into a sigmoid on top of a linear layer \n",
        "    lambdas = torch.sigmoid(self.fc(s_batch))\n",
        "    # Lambda_c is 1-lambda for each weight lambda in lambdas\n",
        "    lambdas_c = torch.add(torch.multiply(lambdas, -1), 1)\n",
        "\n",
        "    return lambdas, lambdas_c"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5tDnIYxxp4y"
      },
      "source": [
        "# Attention layer (additive attention)\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Attention, self).__init__()\n",
        "    self.w = torch.nn.Linear(900, 500)\n",
        "    self.v = nn.Linear(500, 1, bias=False)\n",
        "\n",
        "  def forward(self, enc_template_o, hidden, encoded_kw, mask):\n",
        "    # Unsqueeze for repeat\n",
        "    hidden = hidden.unsqueeze(1)\n",
        "    enc_template_o = enc_template_o.unsqueeze(1)\n",
        "    # Repeat for stacking\n",
        "    hidden = hidden.repeat(1, encoded_kw.size(1), 1)\n",
        "    enc_template_o = enc_template_o.repeat(1, encoded_kw.size(1), 1)\n",
        "    # Conatenate last hidden layer, the encoded keywords and the encoded template\n",
        "    energy = torch.tanh(self.w(torch.cat((hidden, encoded_kw, enc_template_o), dim=2)))\n",
        "    # Calculate score\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "    # Mask\n",
        "    attention = attention.masked_fill(mask == 0, -1e10)\n",
        "\n",
        "    return F.softmax(attention, dim=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmMFzdn85fjS"
      },
      "source": [
        "# Decoder\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, h_size=500, n_layers=4):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.gru = nn.GRU(input_size=1200, hidden_size=500, num_layers=4, batch_first=True, \n",
        "                      dropout=0.5, bidirectional=True)\n",
        "    self.fc = nn.Linear(1000, 200)\n",
        "    self.fc_out = nn.Linear(2200, vocab.n_words)\n",
        "\n",
        "  def forward(self, gru_input, hidden_input):\n",
        "    outputs, hidden = self.gru(gru_input, hidden_input)\n",
        "    # Last hidden layers for attention\n",
        "    last_hidden = torch.tanh(self.fc(torch.cat((hidden[-2], hidden[-1]), dim=1)))\n",
        "    prediction = self.fc_out(torch.cat((outputs.squeeze(1), gru_input.squeeze(1)), dim=1))\n",
        "    return prediction, hidden, last_hidden"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrJgLnPZfMos"
      },
      "source": [
        "# **Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1M-NydnkSdH"
      },
      "source": [
        "Notes to self: \n",
        "- Feed the decoder with the encoder last state\n",
        "- Maybe try without MLP in the encoder.\n",
        "\n",
        "- Read the article in NLP projects folder to decide num of layers of GRU in encoder and decoder\n",
        "\n",
        "- Pack templates going into GRU encoder. Unpack them when going into MLP which reduces dimension\n",
        "\n",
        "- Check how torch.nn.utils.rnn.pad_packed_sequence and torch.nn.utils.rnn.pack_sequence operate (pack a batch, unpack it and pack again and see if it remembers the paddings). probably need pack_padded_sequence for repacking (after unpacking)\n",
        "\n",
        "- Add a dropout layer after embeddings\n",
        "\n",
        "- Try using word2vec https://stackoverflow.com/questions/49710537/pytorch-gensim-how-to-load-pre-trained-word-embeddings/49802495#49802495\n",
        "\n",
        "- Try teacher forcing\n",
        "\n",
        "- For initialization of decoder hidden states, try random noise (or something else) instead of zeros\n",
        "\n",
        "- Consider mask in attention mechanism"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oNmOGfmWfQey"
      },
      "source": [
        "# Initialize the model\n",
        "model = Generator().cuda()\n",
        "\n",
        "# Loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxSsVz5_mw89"
      },
      "source": [
        "# Load saved model\n",
        "\n",
        "#model.load_state_dict(torch.load(\"drive/MyDrive/model_0\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5trGwONroptI"
      },
      "source": [
        "'''def init_weights(m):\n",
        "    for name, param in m.named_parameters():\n",
        "        if 'weight' in name:\n",
        "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
        "        else:\n",
        "            nn.init.constant_(param.data, 0)\n",
        "            \n",
        "model.apply(init_weights)'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnzP5gid0Srn"
      },
      "source": [
        "# Training loop\n",
        "def train_loop(model, n_epochs, train_set):\n",
        "  epoch_loss = 0\n",
        "  \n",
        "  for e in range(1, n_epochs + 1):\n",
        "    for i, (kw, kw_pos, (template, template_len), sentence) in enumerate(train_set, 1):\n",
        "      kw = kw.cuda()\n",
        "      kw_pos = kw_pos.cuda()\n",
        "      template = template.cuda()\n",
        "      sentence = sentence.cuda()\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(kw, kw_pos, (template, template_len), sentence)\n",
        "      loss = criterion(output.reshape(-1, output.shape[-1]), sentence[:, 1:].reshape(-1))\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "      #print(f\"batch {i}\")\n",
        "\n",
        "    # Save model every epoch\n",
        "    torch.save(model.state_dict(), f\"drive/MyDrive/model\") \n",
        "    # Print epoch loss\n",
        "    print(f\"Epoch {e} train loss: {epoch_loss / len(train_set)}\")\n",
        "    # Reset epoch loss\n",
        "    epoch_loss = 0\n",
        "    "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggXYsco21OfX",
        "outputId": "cd3c0444-d572-48dc-ba50-012026a76186"
      },
      "source": [
        "train_loop(model, 40, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 train loss: 2.7816073292350376\n",
            "Epoch 2 train loss: 1.9308604925214725\n",
            "Epoch 3 train loss: 1.687490767063511\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wljQbIIyRC9o"
      },
      "source": [
        "# **TESTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zLuV-JyyHfu"
      },
      "source": [
        "gen = Generator()\n",
        "gen(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxVfkuIQyILR"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9tHopqyRH8u"
      },
      "source": [
        "gen = Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5Gc25akdHME"
      },
      "source": [
        "outputs, hidden, encoded_kw, sentence_embed, lambdas, lambdas_c, context, htt, mt, decoder_input, decoded = gen(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcoaCPU7qb41",
        "outputId": "9e05cc90-7dd3-40ed-ab6a-9d90fe919fa2"
      },
      "source": [
        "outputs.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 5, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmZTsRKCqfFF",
        "outputId": "21a8a2b3-8866-4a40-fcd0-3f907f520ac9"
      },
      "source": [
        "hidden.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZnP3zFMqiIc",
        "outputId": "2d59ee54-b1aa-48e8-cdc1-abf7177903ba"
      },
      "source": [
        "encoded_kw.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb0GmqYRqL_Y"
      },
      "source": [
        "attn = Attention()\n",
        "attn = attn(outputs[:,1,:], hidden, encoded_kw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UigkvZA8pho",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44aa3114-d368-4ae5-8203-b3bea623f25c"
      },
      "source": [
        "attn.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "151rBOEjH_r7"
      },
      "source": [
        "# Context - ct\n",
        "ct = torch.bmm(attn.unsqueeze(1), encoded_kw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdr3jmsGUuRQ",
        "outputId": "98869f04-549b-45e3-a99b-724b33dc90b0"
      },
      "source": [
        "ct.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff9ugp49SZkd",
        "outputId": "32ddb7b0-bfcb-4e25-bb19-38eefce1389d"
      },
      "source": [
        "lambdas.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7z09CS1pTMx_",
        "outputId": "197f698e-7a82-4e4e-c18d-3b5c9227ae03"
      },
      "source": [
        "l = lambdas[:,0,:].unsqueeze(1)\n",
        "l.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMBXdkaJOR4o",
        "outputId": "12877093-5816-4d83-eeb1-c9efe70ab9da"
      },
      "source": [
        "lambdas_c.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 5, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxT1TKpEn2iX",
        "outputId": "03c14ae4-5eb3-4e9d-898f-7bc958509859"
      },
      "source": [
        "lambdas_c[:, 1, :].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1s4lrIJoCp9",
        "outputId": "b3049f6f-6262-4329-c4b1-1ba5c96d6c1a"
      },
      "source": [
        "outputs[:,1,:].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6i5WGg_oGPL",
        "outputId": "d0f9723a-c640-40ce-d01f-1b5663ae19de"
      },
      "source": [
        "(lambdas_c[:, 1, :]*outputs[:,1,:]).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0hVe4J9PQzt",
        "outputId": "4aa25f90-ffe8-41b6-e072-b98320e39505"
      },
      "source": [
        "outputs.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 5, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSxxIKEjNTku",
        "outputId": "77435fb3-5a3f-4da8-a1c9-4847046e0e88"
      },
      "source": [
        "# Template times 1-lambda\n",
        "torch.bmm(lambdas_c.permute(0, 2, 1), outputs).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LLqcZpAVBSe",
        "outputId": "99871319-9da9-4f33-ce91-93514ce8d310"
      },
      "source": [
        "kek = ct*l\n",
        "kek.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eujnd7DWYVLQ",
        "outputId": "a7ecc4e5-5309-4e18-89ce-dfe8087e8ed9"
      },
      "source": [
        "sentence_embed.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 4, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tombwmxmoTD5",
        "outputId": "dd8dd97e-7216-481f-9e0e-6695fc8e2dba"
      },
      "source": [
        "lambdas_c[:, 1, :].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czQS8brboa1G",
        "outputId": "fc25fc50-d58d-44f2-cd8d-678d4178f31e"
      },
      "source": [
        "outputs[:,1,:].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPlxP2bioe4H"
      },
      "source": [
        "kek = lambdas_c[:, 1, :]*outputs[:,1,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN-EeHMyteqo"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lg8B9FFIonI5",
        "outputId": "765c8cb1-f541-48e2-a0bb-e822e2463461"
      },
      "source": [
        "print(htt.size())\n",
        "print(context.size())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256, 1, 200])\n",
            "torch.Size([256, 1, 500])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKjnsAFoQJUx",
        "outputId": "eab3ebcc-0c96-485a-fb07-0f440d5f76ff"
      },
      "source": [
        "mt.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 700])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lic23BEdkYzu",
        "outputId": "0727ad35-e875-49a7-c9e5-acec464a4f28"
      },
      "source": [
        "sentence_embed[:, 0, :].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K56PhPeYoSIw"
      },
      "source": [
        "g = nn.GRU(input_size=1200, hidden_size=500, num_layers=4, batch_first=True, \n",
        "                      dropout=0.5, bidirectional=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQPEhKiJOsqx",
        "outputId": "06c9da5f-8798-4f6a-90be-6f3ba9ebc5c5"
      },
      "source": [
        "decoder_input.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 1200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfgcn-D_PtVQ"
      },
      "source": [
        "o, h = g(decoder_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttl4ggEvWtMs",
        "outputId": "004d2374-a659-4e4d-d500-71c51212dc75"
      },
      "source": [
        "o.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOqIzcd8e_At",
        "outputId": "90a300f1-575f-42ef-a198-d50a4ea21c17"
      },
      "source": [
        "decoded[0].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-qRPqoigkC-"
      },
      "source": [
        "l = nn.Linear(2200, vocab.n_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9Y37fTMhlI3"
      },
      "source": [
        "a = decoded[0].squeeze(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8A_NI1hhoR3",
        "outputId": "1ba7593d-106d-407b-bf87-4b26b0e89069"
      },
      "source": [
        "a.size() == "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oBQ11RFhtOx",
        "outputId": "3b39e503-df41-4ad0-a087-68dcf07a82ef"
      },
      "source": [
        "b = mt.squeeze(1)\n",
        "b.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 700])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcQp8Ye3hyAt",
        "outputId": "ff6c6e63-a007-4c58-c29e-c49f506186f4"
      },
      "source": [
        "c = torch.cat((a, b), dim=1)\n",
        "c.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 1700])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCJytoynogQi"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsMy3QHmo22l"
      },
      "source": [
        "gen = Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX6aDcT0svDO"
      },
      "source": [
        "preds = gen(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EY8reMAxs8Cn",
        "outputId": "e77a5b1d-9c43-48f6-b302-c707d149b6f7"
      },
      "source": [
        "preds.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQZSP6OxIxwj",
        "outputId": "dfbf47a1-95ca-4b09-e7ac-9c4746c7784f"
      },
      "source": [
        "outputs, hidden, encoded_kw, sentence_embed, lambdas, lambdas_c, context, htt, mt, decoder_input = gen(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([256, 200])\n",
            "torch.Size([256, 1000])\n",
            "torch.Size([256, 1000])\n",
            "torch.Size([256, 1000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN-dtr82Lcz",
        "outputId": "43a4ada4-d0d7-4cf0-b4f9-0c63b305bb05"
      },
      "source": [
        "outputs, hidden, encoded_kw, sentence_embed, lambdas, lambdas_c, context, htt, mt, decoder_input = gen(data[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([8, 256, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lVo-5pFJV6b",
        "outputId": "b1bcf22e-9741-4ce8-d474-9bc1991fd2aa"
      },
      "source": [
        "mt.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqOwn_lA2M_v",
        "outputId": "4e1861b7-6e0e-4497-cd21-2ff2e869a5d9"
      },
      "source": [
        "hidden.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 200])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j39XvLZvogva"
      },
      "source": [
        "preds = gen(data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnagYKittlh1",
        "outputId": "c957b3eb-50cd-404a-f740-304e9e9b7386"
      },
      "source": [
        "data[0][2][0].size()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bxcVkmpv7mA",
        "outputId": "b69b4666-5a99-4991-9bfc-fe43542314af"
      },
      "source": [
        "data[0][3].size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([256, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHGRXMIsvnYA"
      },
      "source": [
        "a = torch.tensor([1,2,3,10])\n",
        "b = torch.tensor([4,5,6,11])\n",
        "c = torch.tensor([7,8,9,12])\n",
        "d = torch.stack((a, b, c), dim=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-QbK6EouzDU",
        "outputId": "e0799bea-257f-4e67-83e4-5eb4619fc309"
      },
      "source": [
        "d[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 5, 8])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sszAJwdsuy_Y",
        "outputId": "2e182852-30fa-4c07-b645-04e84eb2fad6"
      },
      "source": [
        "a = torch.tensor([[[1,2,3, 0, 0], [2,1, 0, 0, 0], [2,0,0,0,0]], [[1,2,3, 0, 0], [2,1, 0, 0, 0], [2,0,0,0,0]], [[1,2,3, 0, 0], [2,1, 0, 0, 0], [2,0,0,0,0]]])\n",
        "b = (a != 0)\n",
        "print(b)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ True,  True,  True, False, False],\n",
            "         [ True,  True, False, False, False],\n",
            "         [ True, False, False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True, False, False],\n",
            "         [ True,  True, False, False, False],\n",
            "         [ True, False, False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True, False, False],\n",
            "         [ True,  True, False, False, False],\n",
            "         [ True, False, False, False, False]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0JrieeS6dXK",
        "outputId": "cc3c5cc2-4836-4438-b026-c05bbd754d29"
      },
      "source": [
        "a.size()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8-OvcweoU8B",
        "outputId": "d1bd94be-903e-41aa-9bac-b822fad516b1"
      },
      "source": [
        "c = torch.tensor([[[1,2,3, 4, 5], [6,7, 8, 1, 2], [2,3,4,5,1]], [[1,2,3, 4, 5], [6,7, 8, 1, 2], [2,3,4,5,1]], [[1,2,3, 4, 5], [6,7, 8, 1, 2], [2,3,4,5,1]]])\n",
        "c.masked_fill(b == 0, -1e10)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[           1,            2,            3, -10000000000, -10000000000],\n",
              "         [           6,            7, -10000000000, -10000000000, -10000000000],\n",
              "         [           2, -10000000000, -10000000000, -10000000000, -10000000000]],\n",
              "\n",
              "        [[           1,            2,            3, -10000000000, -10000000000],\n",
              "         [           6,            7, -10000000000, -10000000000, -10000000000],\n",
              "         [           2, -10000000000, -10000000000, -10000000000, -10000000000]],\n",
              "\n",
              "        [[           1,            2,            3, -10000000000, -10000000000],\n",
              "         [           6,            7, -10000000000, -10000000000, -10000000000],\n",
              "         [           2, -10000000000, -10000000000, -10000000000, -10000000000]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlzJxWf8Enrg"
      },
      "source": [
        "embedder = nn.Embedding(num_embeddings=vocab.n_words, embedding_dim=500, padding_idx=0)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWItfWTP6Eke"
      },
      "source": [
        "a = embedder(data[5][0])"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYkQHxanFCfi",
        "outputId": "9071b445-0bec-478f-ee49-c75b7262b4b2"
      },
      "source": [
        "a.size()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 4, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6UgsvV4FD2n"
      },
      "source": [
        "b = a[:,:,0]"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbpNVSKuF0ZT"
      },
      "source": [
        "mask = (a != 0)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsUeCVJCF7vO",
        "outputId": "00d81767-0883-4b19-8915-7398e7cf6dd9"
      },
      "source": [
        "mask.size()"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 4, 500])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUkfwVnSGboA",
        "outputId": "afeb1196-d8b6-4f1f-ae6b-5aaddf923651"
      },
      "source": [
        "mask[0]"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ True,  True,  True,  ...,  True,  True,  True],\n",
              "        [ True,  True,  True,  ...,  True,  True,  True],\n",
              "        [False, False, False,  ..., False, False, False],\n",
              "        [False, False, False,  ..., False, False, False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ILT_dqBGt6N",
        "outputId": "168fa0cc-5e5e-465c-fea3-06971721619f"
      },
      "source": [
        "torch.any(mask, dim=2)[0]"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ True,  True, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3YXqLr6H1D2",
        "outputId": "42dde3ac-713c-402b-c298-a382384f6676"
      },
      "source": [
        "torch.any(mask, dim=2).size()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-GJJrOtFvvz",
        "outputId": "e4f4b539-9bb5-414a-bd24-c8ddb956c35a"
      },
      "source": [
        "b.size()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    }
  ]
}